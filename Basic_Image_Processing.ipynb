{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OnFkvEuzswQ"
      },
      "source": [
        "# **INTRODUCTION TO BASIC IMAGE PROCESSING**\n",
        "---\n",
        "## **INTRO**\n",
        "This is simple introduction to image processing in python. This *Google Colab* notebook is fully interactive and you can run it yourself. Today you will learn 3 basic principles in image processing:\n",
        "1. What is image?\n",
        "  * how image is stored\n",
        "  * how image is perceived\n",
        "  * basic programming and linear algebra\n",
        "2. what is image processing?\n",
        "  * types of operations on image\n",
        "  * image transformation\n",
        "    * chanel transformation\n",
        "    * intensity transformation\n",
        "    * convolution \n",
        "3. Advanced topics:\n",
        "  * Face detection\n",
        "  * Convolutional Neural Networks:\n",
        "  * Computer Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiBiy4tu2cVV"
      },
      "source": [
        "---\n",
        "# **What is image?**\n",
        "\n",
        "Image is 2 dimensional an array (matrix) of pixels, with 3 chanels (red, green,blue) with 8-bits of value for each chanel in single pixel. \n",
        "\n",
        "for example:\n",
        "Here is 8bit data: (0000 0111) <base 2>  == 7 <base 10>\n",
        "\n",
        "(1111 1111)<base 2> == 255 <base 10>\n",
        "\n",
        "(0000 0000)<base 2> == 0 <base 10>\n",
        "\n",
        "3chanels = ((0000 0000),(1111 1111),(1000 0111)) == (0,255,7)  \n",
        "\n",
        "above number certain color!\n",
        "\n",
        "If you wonder what is this color? Run the next code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_OVuhNZvMHq"
      },
      "source": [
        "# everything after # is a comment! \n",
        "\n",
        "import cv2 #library for opencv (OPEN SOURCE COMPUTER VISION)\n",
        "import numpy as np # library of numpy - numerical python \n",
        "from matplotlib import pyplot as plt # python library to plot images or data in a nice format: \n",
        "\n",
        "im = np.zeros((10,20,3),np.uint8) # creats height = 10 by width = 20 image, with 3 chanels (red,green,blue) , with 8-bit data \n",
        "\n",
        "for i in range(10):\n",
        "  for j in range(20):\n",
        "    im[i,j,:] = [0,255,7]\n",
        "\n",
        "plt.imshow(im) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L7gsd5T6HQh"
      },
      "source": [
        "# YAY! WHO have thought! This is green image!\n",
        "\n",
        "Red= 0; (min) \n",
        "\n",
        "Green = 255 (max)\n",
        "\n",
        "Blue = 7 (little bit)\n",
        "\n",
        "so output image is green. You can play around and assign different value than [0,255,7]. Try for example [255,0,0].\n",
        "\n",
        "\n",
        "---\n",
        "How image is stored? Lets download something else and see what happens. Here you can see how to directly download image to your google colab from remote URL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2eOV9IkvO43",
        "outputId": "0be02c9c-7ee2-4e97-e7fc-550c558ec946"
      },
      "source": [
        "#this code gets image from below url and stores it in the name \" dt.jpg. \".  \n",
        "!wget \"https://static6.depositphotos.com/1167801/651/i/950/depositphotos_6517777-stock-photo-rainbow-of-colorful-boxes.jpg\" -O dt.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-11 13:15:18--  https://static6.depositphotos.com/1167801/651/i/950/depositphotos_6517777-stock-photo-rainbow-of-colorful-boxes.jpg\n",
            "Resolving static6.depositphotos.com (static6.depositphotos.com)... 23.199.163.120\n",
            "Connecting to static6.depositphotos.com (static6.depositphotos.com)|23.199.163.120|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88693 (87K) [image/jpeg]\n",
            "Saving to: ‘dt.jpg’\n",
            "\n",
            "\rdt.jpg                0%[                    ]       0  --.-KB/s               \rdt.jpg              100%[===================>]  86.61K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-12-11 13:15:18 (3.47 MB/s) - ‘dt.jpg’ saved [88693/88693]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBrder9g8tfK"
      },
      "source": [
        "Keep in mind: there are different formats to store images. They divide in 2 types: \n",
        "  1. Lossless - no data is lost (.png, .RAW, .BMP )\n",
        "  2. Lossy - data might get corrupted (.jpg, .JPEG, .WebP)\n",
        "\n",
        "Why use both? \n",
        "Lossless images are expensive in memory: some images are can get up to 1-10 GB.\n",
        "Lossy images get corrupted - after many copies image becomes too corruped.\n",
        "\n",
        "#Example of Image corruption:\n",
        "<img src =\"https://i.stack.imgur.com/U7Q3A.jpg\" width=\"400px\" height = \"300px\">\n",
        "\n",
        "#Compression artifact of JPEG after several iteration:\n",
        "<img src =\"https://hsto.org/webt/oa/dz/7l/oadz7ljyuu-vouck3fsoafeulis.jpeg\" width=\"700px\" height = \"200px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2oKAE00-doe"
      },
      "source": [
        "\n",
        "###Lets open image. In order to open it, we will use opencv functionality. Here is how you open the image:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIJ0IRYdvRKF"
      },
      "source": [
        "img = cv2.imread('./dt.jpg')\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5T6YHwl8VWX"
      },
      "source": [
        "##HOW TO FIND THE SIZE OF THE IMAGE?\n",
        "\n",
        "its all right. Opencv already has interface for that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FM4fhDmgvW36",
        "outputId": "032e9710-4008-45f2-abd3-b9daffcb269e"
      },
      "source": [
        "print(img.shape) #prints as output the size of your image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(682, 1023, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDzXbDQj9CV5"
      },
      "source": [
        "#**2. IMAGE PROCESSING**\n",
        "\n",
        "### This is interesting part of the tutorial. I will show you how to perform some operations on images. There are 3 types of operations you can do on images. \n",
        "\n",
        "### 1. ***Image cropping and Rotation***\n",
        "\n",
        "It is pretty easy task, but you should understand how images are actually cropped and resized by the avaiable tools in programs like *Photoshop* or *Krita*. \n",
        "\n",
        "Image \"dt.jpg\" that we downloaded is of size (682,1023,3), for height,width and number of chanels. Lets see what happens if we crop half of the image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHZDhqP7C0Gc"
      },
      "source": [
        "H,W = img.shape[:2]\n",
        "new_image = np.zeros((H,int(W/2),3),np.uint8)\n",
        "for i in range(H):\n",
        "  for j in range(int(W/2)):\n",
        "    new_image[i,j] = img[i,j]\n",
        "\n",
        "plt.imshow(new_image)\n",
        "plt.show()\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7KnJAeIEp0R"
      },
      "source": [
        "###Image Rotation For 90 degrees clockwise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eapbL4CfEpGU"
      },
      "source": [
        "H,W = img.shape[:2]\n",
        "new_image = np.zeros((W,H,3),np.uint8)\n",
        "for i in range(H):\n",
        "  for j in range(W):\n",
        "    new_image[j,i] = img[i,j]\n",
        "plt.figure(figsize = (6,6))\n",
        "plt.imshow(new_image)\n",
        "plt.show()\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on_q6b7XGQDn"
      },
      "source": [
        "# **Pixelwise operations:**\n",
        "#### This operations are performed equally on each pixel of the image. As you may wonder, how can you create gray-scale (black and white) image? This operation is done by pixel-wise operation! Here is example:\n",
        "---\n",
        "### *** Gray scale Image:*** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "m59D3NLuwinQ",
        "outputId": "d834ead9-c259-48e5-e770-63ead6327e49"
      },
      "source": [
        "# first generate fully black image:\n",
        "\n",
        "H,W = img.shape[:2]\n",
        "gray = np.zeros((H,W), np.uint8)\n",
        "plt.imshow(gray,cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4c53226b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc6VS2iNHMpR"
      },
      "source": [
        "#### Naive Gray Scale Image: tage *grayscale_channel = (red_chanel + blue_chanel + green_chanel) / 3*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pg48bL8w9y7"
      },
      "source": [
        "# Naive Gray Scale Image: tage grayscale_channel = red_pixel\n",
        "for i in range(H):\n",
        "  for j in range(W):\n",
        "    gray[i,j] = np.clip( img[i,j,0]/3.0  +  img[i,j,1]/3.0 +  img[i,j,2]/3.0, 0, 255)\n",
        "  \n",
        "plt.imshow(gray,cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALqpNfiuHhMj"
      },
      "source": [
        "<img src= \"https://i.imgur.com/EaaHUWF.jpg\" width = \"200px\" height = \"200px\">\n",
        "\n",
        "#WE LOST OUR COLORS!!!!\n",
        "\n",
        "The reason is that if you take average of all 3 chanels, then it becomes indistinguishable from each other. However, there are several ways to get around it. One of them is instead of assigning each chanel multiplier of *1/3* we can give different values as in the following example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egKfuTUMygZh"
      },
      "source": [
        "for i in range(H):\n",
        "  for j in range(W):\n",
        "    gray[i,j] = np.clip(0.07 * img[i,j,0]  + 0.72 * img[i,j,1] + 0.21 * img[i,j,2], 0, 255)\n",
        "\n",
        "plt.imshow(gray,cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbciQzWCIgd3"
      },
      "source": [
        "#YAY, WE PRESEVED THE COLOR INFORMATION !!!\n",
        "####Almost\n",
        "\n",
        "###There are other Interesting operations, for example [Histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX6gP35hJIHD"
      },
      "source": [
        "# **Convolution**\n",
        "\n",
        "###This is going to be fun. You may have already heard this word many times, so its finally time to understand [what it means](https://en.wikipedia.org/wiki/Convolution)\n",
        "\n",
        "####In image processing, convolution is special type of operation. In order to perform operation, the image is multiplied by ***filter*** also called ***kernel***. kernel is also an image, but often of smaller size. for example, it can be image of size (2,2,3) - simplest kernel. \n",
        "\n",
        "#### Above example of pixelwise multiplication is also Convolution operation with kernel size (1,1,3). values of the kernel is:\n",
        "\n",
        "#### k(0,0,0) = 0.07  \n",
        "#### k(0,0,1) = 0.72 \n",
        "#### k(0,0,2) = 0.21\n",
        "\n",
        "### Here is visual demonstration of convolution operation on single chanel image: \n",
        "![](http://d2l.ai/_images/correlation.svg)\n",
        "\n",
        "###Kernel is :\n",
        "\n",
        "#### k(0,0,0) = 0  \n",
        "#### k(0,1,0) = 1 \n",
        "#### k(1,0,0) = 2\n",
        "#### k(0,1,0) = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTYyMCRDQWv2"
      },
      "source": [
        "### Here is function to perform convolution operation: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB7g9tAuJHTn"
      },
      "source": [
        "def convolution(image,kernel):\n",
        "  (H,W) = image.shape[:2]\n",
        "  (kH,kW) = kernel.shape[:2]\n",
        "  \n",
        "  pad = (kW-1)//2\n",
        "\n",
        "  image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
        "  output = np.zeros((H, W), dtype=\"float32\")\n",
        "  for y in np.arange(pad, H + pad):\n",
        "    for x in np.arange(pad, W + pad):\n",
        "      regionOfInteset = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
        "      convolutionPixel = (regionOfInteset * kernel).sum()\n",
        "      output[y - pad, x - pad] = np.clip(convolutionPixel,0,255)\n",
        "\n",
        "  #output = rescale_intensity(output, in_range=(0, 255))\n",
        "  output = (output).astype(\"uint8\")\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1Rfs3QrQpfl"
      },
      "source": [
        "### Here is example on how to use it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djt4wi7BQoFB"
      },
      "source": [
        "smallBlur = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n",
        "bigBlur = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))\n",
        "\n",
        "smallBlurry = convolution(gray,smallBlur)\n",
        "bigBluryy = convolution(gray,bigBlur)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOk-m8PcRnrO"
      },
      "source": [
        "plt.imshow(gray,cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(smallBlurry,cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(bigBluryy,cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV037ICTfvlQ"
      },
      "source": [
        "###With convolution, you can do something more abstract. For example, you can find vertical lines and horizontal lines in image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTqLm7VYUTLv"
      },
      "source": [
        "# construct the Sobel x-axis kernel\n",
        "sobelX = np.array((\n",
        "\t[-1, 0, 1],\n",
        "\t[-2, 0, 2],\n",
        "\t[-1, 0, 1]), dtype=\"int\")\n",
        "# construct the Sobel y-axis kernel\n",
        "sobelY = np.array((\n",
        "\t[-1, -2, -1],\n",
        "\t[0, 0, 0],\n",
        "\t[1, 2, 1]), dtype=\"int\")\n",
        "\n",
        "horisontalEdgeFinder = convolution(gray,sobelX)\n",
        "verticalEdgeFinder = convolution(gray,sobelY)\n",
        "\n",
        "plt.imshow(gray,cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(horisontalEdgeFinder,cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(verticalEdgeFinder,cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAlslyuzgFly"
      },
      "source": [
        "### Higher intensity means the lines are \"more vertical\" or \"more horizontal\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yns3awxCVX3r"
      },
      "source": [
        "# ADVANCED TOPICS IN IMAGE PROCESSING:\n",
        "\n",
        "## ***1. Face detection***\n",
        "\n",
        "####It is contr-intuitive, but face detection is also done using convolution operation. Here is example of face detection kernels:\n",
        "\n",
        "![](https://www.machinelearningmastery.ru/img/0-116498-321743.png)\n",
        "\n",
        "Rough idea of how face detection works:\n",
        "\n",
        "1. Each kernel returns position of some feature (eyes, eyebrows, nose, mouse)\n",
        "2. Each of 20 kernels create a single channel\n",
        "3. all channels are merged to single 20-channel image (instead of 3-chanel rgb)\n",
        "4. then, single kernel of size (N,N,20) applied to total image.\n",
        "    * This kernel basically needs perfect combination for each values. It is hard to design, but idea is that you need 2 yes, one nose and one mouth to detect face\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31P-MVQmZhIA"
      },
      "source": [
        "# **Convolutional Neural Network**\n",
        "\n",
        "##You may already notised something:\n",
        "\n",
        "#*ALL IMAGE BASED OPERATIONS ARE CONVOLUTIONS!*\n",
        "\n",
        "### Insight for CNN:\n",
        "1. Finding/Design of kernel values are hard task\n",
        "2. Almost every image transformation is convolution operation\n",
        "3. Machine learning can be used to find appropriate filters (kernels!). \n",
        "\n",
        "##Here is Architecture of Alex-net:\n",
        "![](https://www.researchgate.net/profile/Walid_Aly/publication/312188377/figure/fig4/AS:448996423540740@1484060497977/An-illustration-of-the-architecture-of-AlexNet-CNN-14.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6ZrOY_ia31P"
      },
      "source": [
        "#COMPUTER VISION\n",
        "\n",
        "###Computer vision tries to solve this problem: \n",
        "###*How to make computers understand what is depicted on image?* \n",
        "\n",
        "###or \n",
        "###*How to make computers perceive and understand the world?*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "896DXZEXe4EV"
      },
      "source": [
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7ztK5AhShqU\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "8Q-RG0tIecjY",
        "outputId": "89fc8e31-9238-4a63-9c68-62e20fd732c6"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7ztK5AhShqU\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7ztK5AhShqU\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    }
  ]
}